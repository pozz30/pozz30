{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 재현 가능한 난수 생성\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "def load_data():\n",
    "    n = 2000\n",
    "    split = 0.8\n",
    "    n_train = (int)(split*n)\n",
    "    \n",
    "    y = np.random.randint(28, size=(n,2))\n",
    "    x = np.empty((n,28,28))\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        img = np.zeros((28,28))\n",
    "        cv2.circle(img, (y[i][0],y[i][1]), 3, 255, -1)\n",
    "        x[i] = img\n",
    "    return ((x[:n_train], y[:n_train]), (x[n_train:], y[n_train:]))\n",
    "\n",
    "def label(y):\n",
    "    return np.around(y).astype('int')\n",
    "        \n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# normalize image\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(str(label(y_test[i])))\n",
    "plt.show()\n",
    "\n",
    "def pos_accuracy(y_true, y_pred):\n",
    "    label_true = tf.round(y_true)\n",
    "    label_pred = tf.round(y_pred)\n",
    "    is_correct = tf.reduce_all(label_true == label_pred, axis=1)\n",
    "    is_correct = tf.cast(is_correct, 'float32')\n",
    "    score = tf.reduce_mean(is_correct)\n",
    "    return score\n",
    "\n",
    "input_layer = Input((28, 28))\n",
    "x = Flatten()(input_layer)\n",
    "#\n",
    "# 여기에 Dense Layer를 복수개 추가하여야합니다.\n",
    "#\n",
    "output_layer = Dense(2, activation = None)(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "summary_list = []\n",
    "model.summary(print_fn=lambda x: summary_list.append(x))\n",
    "for line in summary_list:\n",
    "    print(line)\n",
    "\n",
    "# learning_rate를 알맞게 변경해 봅시다.\n",
    "# 적절한 학습 속도를 보장하면서도, 높은 정확도를 보이도록 튜닝합시다.  \n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='mse', metrics=[pos_accuracy])\n",
    "\n",
    "# custom metric을 추가하고 batch_size와 epochs를 변경하면서 실험해 봅시다.\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size = 64, epochs=2)\n",
    "\n",
    "\n",
    "# Dense 모델의 노드 수를 list형식으로 다음 변수에 기록합니다.\n",
    "# 두 개의 은닉층을 사용하고 첫 은닉층의 노드 수가 32이고 두번째 은닉층의 노드 수가 64일 때:\n",
    "ans11 = [32, 64] \n",
    "\n",
    "# 모델의 요약 string을 다음 변수에 기록합니다.\n",
    "ans12 = summary_list\n",
    "\n",
    "# learning_rate\n",
    "ans13 = 0.001\n",
    "# batch_size\n",
    "ans14 = 64\n",
    "# 학습 epoch 수\n",
    "ans15 = 2\n",
    "# 최종 val_loss 결과\n",
    "ans16 = 54.7178\n",
    "# 최종 val_pos_accuracy 결과\n",
    "ans17 = 0.91\n",
    "\n",
    "ans18 = \"\"\"\n",
    "tf.reduce_all의 역할은 무엇인지, axis=1은 무엇을 의미하는 지 간단히 요약해 봅시다.\n",
    "-> reduce_all 은 tensor가 지정한 축 방향의 각 요소의 논리와 (and 연산) 계산하는 함수이다.\n",
    "\"\"\"\n",
    "\n",
    "ans19 = \"\"\"\n",
    "tf.reduce_mean은 코드에서 어떤 역할을 하는지, 간단히 요약해 봅시다. \n",
    "-> reduce_mean 은 특정 차원을 제거하고 평균을 구하는 함수이다.\n",
    "\"\"\"\n",
    "\n",
    "ans20 = \"\"\"\n",
    "최종 출력층의 activation=None인 이유\n",
    "활성화 함수가 없는 경우 신경망 학습은 선형회귀와 동일하기 때문이다.\n",
    "\"\"\"\n",
    "\n",
    "ans21 = \"\"\"\n",
    "random seed의 사용 이유\n",
    "컴퓨터 내 내장된 랜덤 테이블 중 랜덤 테이블 어떤 것을 불러올 것인지 결정 (seed값이 같으면 똑같은 랜덤 값 출력)\n",
    "→ 일정한 결과값을 얻기 위해서는 넘파이 seed값과 텐서플로 seed값 모두 설정해야 함\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
